{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnanthSankaralingam/AnanthSankaralingam/blob/main/llama_attention_scores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6LcqCCwxQz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a728f3-0726-4e02-c8bb-aead4a117038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama3'...\n",
            "remote: Enumerating objects: 407, done.\u001b[K\n",
            "remote: Counting objects: 100% (224/224), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 407 (delta 189), reused 140 (delta 133), pack-reused 183\u001b[K\n",
            "Receiving objects: 100% (407/407), 597.86 KiB | 4.71 MiB/s, done.\n",
            "Resolving deltas: 100% (235/235), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/meta-llama/llama3.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1HS_jQ3xWA4",
        "outputId": "d7ab3655-ca51-4c18-afb6-ae46871345eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2mIWlbJxZwd",
        "outputId": "4ede7eb0-375c-4124-d9b4-c64f1eaa8a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/llama3\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.3.0+cu121)\n",
            "Collecting fairscale (from -r requirements.txt (line 2))\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fire (from -r requirements.txt (line 3))\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tiktoken==0.4.0 (from -r requirements.txt (line 4))\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blobfile (from -r requirements.txt (line 5))\n",
            "  Downloading blobfile-2.1.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0->-r requirements.txt (line 4)) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1)) (12.5.40)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from fairscale->-r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 3)) (2.4.0)\n",
            "Collecting pycryptodomex~=3.8 (from blobfile->-r requirements.txt (line 5))\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile->-r requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->-r requirements.txt (line 5)) (4.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0->-r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0->-r requirements.txt (line 4)) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: fairscale, fire\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332108 sha256=d1a6767b73a2a05af81c7900ed6b2a701e400de40db2712c1b3bde5755a82194\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117029 sha256=0acbf5fe3f982b1554ea960cdeea14689fcca0054d52f8096e841cbabae0a58e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
            "Successfully built fairscale fire\n",
            "Installing collected packages: pycryptodomex, fire, tiktoken, blobfile, fairscale\n",
            "Successfully installed blobfile-2.1.1 fairscale-0.4.13 fire-0.6.0 pycryptodomex-3.20.0 tiktoken-0.4.0\n"
          ]
        }
      ],
      "source": [
        "%cd llama3\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x01v5apyoLYr"
      },
      "source": [
        "**Visit https://llama.meta.com/llama-downloads and download LLaMA 3, then input download URL and desired weight (8B)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diyeB30myqoD",
        "outputId": "1ef934b9-fd2b-4524-848d-508ece48672e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the URL from email: https://download6.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoicTZpdHY5NmZwMGxna3dnN2Z3aDZ0M3FlIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQ2LmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3MTgwODI3MDl9fX1dfQ__&Signature=IdF-MUKQ77VfvnNT8Dp0tVVyX8amMJLWDDvQnSHIs6uEpvSmsHLV-HjteHJEPd-rZcCUMGK1ghRTMOs1XahZGvq56fU8ewFF6IrnbpgbXMIzigdM22foaOtDZPO3zdTkiO13NXRHIoV5M5VfdUgTn2q2U9CcNixP-a8GlE35vVHh99dMU9aWFHu7akYnX77yzmKy2nBnUGWajsxD8h6AGhOAVJA3D4hKot%7EPKUAb6yuQTktwfA5dYNVzLHpIpUGZXOMbPFk5j3%7E4QQoOZVNJ0MJG5vuZutnFqyQHN-NK2YfkMhPMGI4LeQpQkZ4t3YFJEOhdvqfFV7lgKaLl6D1l%7Eg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=948820063657069\n",
            "\n",
            "Enter the list of models to download without spaces (8B,8B-instruct,70B,70B-instruct), or press Enter for all: 8b\n",
            "Downloading LICENSE and Acceptable Usage Policy\n",
            "--2024-06-10 05:13:29--  https://download6.llamameta.net/LICENSE?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoicTZpdHY5NmZwMGxna3dnN2Z3aDZ0M3FlIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQ2LmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3MTgwODI3MDl9fX1dfQ__&Signature=IdF-MUKQ77VfvnNT8Dp0tVVyX8amMJLWDDvQnSHIs6uEpvSmsHLV-HjteHJEPd-rZcCUMGK1ghRTMOs1XahZGvq56fU8ewFF6IrnbpgbXMIzigdM22foaOtDZPO3zdTkiO13NXRHIoV5M5VfdUgTn2q2U9CcNixP-a8GlE35vVHh99dMU9aWFHu7akYnX77yzmKy2nBnUGWajsxD8h6AGhOAVJA3D4hKot%7EPKUAb6yuQTktwfA5dYNVzLHpIpUGZXOMbPFk5j3%7E4QQoOZVNJ0MJG5vuZutnFqyQHN-NK2YfkMhPMGI4LeQpQkZ4t3YFJEOhdvqfFV7lgKaLl6D1l%7Eg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=948820063657069\n",
            "Resolving download6.llamameta.net (download6.llamameta.net)... 18.154.185.48, 18.154.185.52, 18.154.185.103, ...\n",
            "Connecting to download6.llamameta.net (download6.llamameta.net)|18.154.185.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2024-06-10 05:13:30--  https://download6.llamameta.net/USE_POLICY?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoicTZpdHY5NmZwMGxna3dnN2Z3aDZ0M3FlIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQ2LmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3MTgwODI3MDl9fX1dfQ__&Signature=IdF-MUKQ77VfvnNT8Dp0tVVyX8amMJLWDDvQnSHIs6uEpvSmsHLV-HjteHJEPd-rZcCUMGK1ghRTMOs1XahZGvq56fU8ewFF6IrnbpgbXMIzigdM22foaOtDZPO3zdTkiO13NXRHIoV5M5VfdUgTn2q2U9CcNixP-a8GlE35vVHh99dMU9aWFHu7akYnX77yzmKy2nBnUGWajsxD8h6AGhOAVJA3D4hKot%7EPKUAb6yuQTktwfA5dYNVzLHpIpUGZXOMbPFk5j3%7E4QQoOZVNJ0MJG5vuZutnFqyQHN-NK2YfkMhPMGI4LeQpQkZ4t3YFJEOhdvqfFV7lgKaLl6D1l%7Eg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=948820063657069\n",
            "Resolving download6.llamameta.net (download6.llamameta.net)... 18.154.185.48, 18.154.185.52, 18.154.185.103, ...\n",
            "Connecting to download6.llamameta.net (download6.llamameta.net)|18.154.185.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8800 (8.6K) [binary/octet-stream]\n",
            "Saving to: ‘./USE_POLICY’\n",
            "\n",
            "./USE_POLICY        100%[===================>]   8.59K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-06-10 05:13:30 (13.9 MB/s) - ‘./USE_POLICY’ saved [8800/8800]\n",
            "\n",
            "Downloading 8b_pre_trained\n",
            "--2024-06-10 05:13:30--  https://download6.llamameta.net/8b_pre_trained/consolidated.00.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoicTZpdHY5NmZwMGxna3dnN2Z3aDZ0M3FlIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQ2LmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3MTgwODI3MDl9fX1dfQ__&Signature=IdF-MUKQ77VfvnNT8Dp0tVVyX8amMJLWDDvQnSHIs6uEpvSmsHLV-HjteHJEPd-rZcCUMGK1ghRTMOs1XahZGvq56fU8ewFF6IrnbpgbXMIzigdM22foaOtDZPO3zdTkiO13NXRHIoV5M5VfdUgTn2q2U9CcNixP-a8GlE35vVHh99dMU9aWFHu7akYnX77yzmKy2nBnUGWajsxD8h6AGhOAVJA3D4hKot%7EPKUAb6yuQTktwfA5dYNVzLHpIpUGZXOMbPFk5j3%7E4QQoOZVNJ0MJG5vuZutnFqyQHN-NK2YfkMhPMGI4LeQpQkZ4t3YFJEOhdvqfFV7lgKaLl6D1l%7Eg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=948820063657069\n",
            "Resolving download6.llamameta.net (download6.llamameta.net)... 18.154.185.48, 18.154.185.52, 18.154.185.103, ...\n",
            "Connecting to download6.llamameta.net (download6.llamameta.net)|18.154.185.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16060617592 (15G) [binary/octet-stream]\n",
            "Saving to: ‘./Meta-Llama-3-8B/consolidated.00.pth’\n",
            "\n",
            "./Meta-Llama-3-8B/c 100%[===================>]  14.96G   327MB/s    in 49s     \n",
            "\n",
            "2024-06-10 05:14:19 (315 MB/s) - ‘./Meta-Llama-3-8B/consolidated.00.pth’ saved [16060617592/16060617592]\n",
            "\n",
            "--2024-06-10 05:14:19--  https://download6.llamameta.net/8b_pre_trained/params.json?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoicTZpdHY5NmZwMGxna3dnN2Z3aDZ0M3FlIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQ2LmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3MTgwODI3MDl9fX1dfQ__&Signature=IdF-MUKQ77VfvnNT8Dp0tVVyX8amMJLWDDvQnSHIs6uEpvSmsHLV-HjteHJEPd-rZcCUMGK1ghRTMOs1XahZGvq56fU8ewFF6IrnbpgbXMIzigdM22foaOtDZPO3zdTkiO13NXRHIoV5M5VfdUgTn2q2U9CcNixP-a8GlE35vVHh99dMU9aWFHu7akYnX77yzmKy2nBnUGWajsxD8h6AGhOAVJA3D4hKot%7EPKUAb6yuQTktwfA5dYNVzLHpIpUGZXOMbPFk5j3%7E4QQoOZVNJ0MJG5vuZutnFqyQHN-NK2YfkMhPMGI4LeQpQkZ4t3YFJEOhdvqfFV7lgKaLl6D1l%7Eg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=948820063657069\n",
            "Resolving download6.llamameta.net (download6.llamameta.net)... 18.154.185.52, 18.154.185.103, 18.154.185.37, ...\n",
            "Connecting to download6.llamameta.net (download6.llamameta.net)|18.154.185.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211 [application/json]\n",
            "Saving to: ‘./Meta-Llama-3-8B/params.json’\n",
            "\n",
            "./Meta-Llama-3-8B/p 100%[===================>]     211  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-10 05:14:19 (2.65 MB/s) - ‘./Meta-Llama-3-8B/params.json’ saved [211/211]\n",
            "\n",
            "--2024-06-10 05:14:19--  https://download6.llamameta.net/8b_pre_trained/tokenizer.model?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoicTZpdHY5NmZwMGxna3dnN2Z3aDZ0M3FlIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQ2LmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3MTgwODI3MDl9fX1dfQ__&Signature=IdF-MUKQ77VfvnNT8Dp0tVVyX8amMJLWDDvQnSHIs6uEpvSmsHLV-HjteHJEPd-rZcCUMGK1ghRTMOs1XahZGvq56fU8ewFF6IrnbpgbXMIzigdM22foaOtDZPO3zdTkiO13NXRHIoV5M5VfdUgTn2q2U9CcNixP-a8GlE35vVHh99dMU9aWFHu7akYnX77yzmKy2nBnUGWajsxD8h6AGhOAVJA3D4hKot%7EPKUAb6yuQTktwfA5dYNVzLHpIpUGZXOMbPFk5j3%7E4QQoOZVNJ0MJG5vuZutnFqyQHN-NK2YfkMhPMGI4LeQpQkZ4t3YFJEOhdvqfFV7lgKaLl6D1l%7Eg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=948820063657069\n",
            "Resolving download6.llamameta.net (download6.llamameta.net)... 18.154.185.52, 18.154.185.103, 18.154.185.37, ...\n",
            "Connecting to download6.llamameta.net (download6.llamameta.net)|18.154.185.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2183982 (2.1M) [binary/octet-stream]\n",
            "Saving to: ‘./Meta-Llama-3-8B/tokenizer.model’\n",
            "\n",
            "./Meta-Llama-3-8B/t 100%[===================>]   2.08M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-06-10 05:14:19 (26.4 MB/s) - ‘./Meta-Llama-3-8B/tokenizer.model’ saved [2183982/2183982]\n",
            "\n",
            "--2024-06-10 05:14:19--  https://download6.llamameta.net/8b_pre_trained/checklist.chk?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoicTZpdHY5NmZwMGxna3dnN2Z3aDZ0M3FlIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQ2LmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3MTgwODI3MDl9fX1dfQ__&Signature=IdF-MUKQ77VfvnNT8Dp0tVVyX8amMJLWDDvQnSHIs6uEpvSmsHLV-HjteHJEPd-rZcCUMGK1ghRTMOs1XahZGvq56fU8ewFF6IrnbpgbXMIzigdM22foaOtDZPO3zdTkiO13NXRHIoV5M5VfdUgTn2q2U9CcNixP-a8GlE35vVHh99dMU9aWFHu7akYnX77yzmKy2nBnUGWajsxD8h6AGhOAVJA3D4hKot%7EPKUAb6yuQTktwfA5dYNVzLHpIpUGZXOMbPFk5j3%7E4QQoOZVNJ0MJG5vuZutnFqyQHN-NK2YfkMhPMGI4LeQpQkZ4t3YFJEOhdvqfFV7lgKaLl6D1l%7Eg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=948820063657069\n",
            "Resolving download6.llamameta.net (download6.llamameta.net)... 18.154.185.52, 18.154.185.103, 18.154.185.37, ...\n",
            "Connecting to download6.llamameta.net (download6.llamameta.net)|18.154.185.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 150 [binary/octet-stream]\n",
            "Saving to: ‘./Meta-Llama-3-8B/checklist.chk’\n",
            "\n",
            "./Meta-Llama-3-8B/c 100%[===================>]     150  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-10 05:14:20 (184 MB/s) - ‘./Meta-Llama-3-8B/checklist.chk’ saved [150/150]\n",
            "\n",
            "Checking checksums\n",
            "consolidated.00.pth: OK\n",
            "params.json: OK\n",
            "tokenizer.model: OK\n"
          ]
        }
      ],
      "source": [
        "!chmod +x download.sh\n",
        "!./download.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRREBmhs0rCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc1a088-9ef5-456c-e819-b1af67d110cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/llama3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from llama3==0.0.1) (2.3.0+cu121)\n",
            "Requirement already satisfied: fairscale in /usr/local/lib/python3.10/dist-packages (from llama3==0.0.1) (0.4.13)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from llama3==0.0.1) (0.6.0)\n",
            "Requirement already satisfied: tiktoken==0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama3==0.0.1) (0.4.0)\n",
            "Requirement already satisfied: blobfile in /usr/local/lib/python3.10/dist-packages (from llama3==0.0.1) (2.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0->llama3==0.0.1) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.4.0->llama3==0.0.1) (2.31.0)\n",
            "Requirement already satisfied: pycryptodomex~=3.8 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama3==0.0.1) (3.20.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama3==0.0.1) (2.0.7)\n",
            "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama3==0.0.1) (4.9.4)\n",
            "Requirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile->llama3==0.0.1) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from fairscale->llama3==0.0.1) (1.25.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->llama3==0.0.1) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->llama3==0.0.1) (12.5.40)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llama3==0.0.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llama3==0.0.1) (2.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0->llama3==0.0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0->llama3==0.0.1) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.4.0->llama3==0.0.1) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->llama3==0.0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->llama3==0.0.1) (1.3.0)\n",
            "Installing collected packages: llama3\n",
            "  Running setup.py develop for llama3\n",
            "Successfully installed llama3-0.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed4spTKx6YQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555d0001-0159-405a-e9df-4f20e4c054f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Showing help with the command 'example_chat_completion.py -- --help'.\n",
            "\n",
            "\u001b[1mNAME\u001b[0m\n",
            "    example_chat_completion.py - Examples to run with the models finetuned for chat. Prompts correspond of chat turns between the user and assistant with the final one always being the user.\n",
            "\n",
            "\u001b[1mSYNOPSIS\u001b[0m\n",
            "    example_chat_completion.py \u001b[4mCKPT_DIR\u001b[0m \u001b[4mTOKENIZER_PATH\u001b[0m <flags>\n",
            "\n",
            "\u001b[1mDESCRIPTION\u001b[0m\n",
            "    An optional system prompt at the beginning to control how the model should respond\n",
            "    is also supported.\n",
            "\n",
            "    The context window of llama3 models is 8192 tokens, so `max_seq_len` needs to be <= 8192.\n",
            "\n",
            "    `max_gen_len` is optional because finetuned models are able to stop generations naturally.\n",
            "\n",
            "\u001b[1mPOSITIONAL ARGUMENTS\u001b[0m\n",
            "    \u001b[1m\u001b[4mCKPT_DIR\u001b[0m\u001b[0m\n",
            "        Type: str\n",
            "    \u001b[1m\u001b[4mTOKENIZER_PATH\u001b[0m\u001b[0m\n",
            "        Type: str\n",
            "\n",
            "\u001b[1mFLAGS\u001b[0m\n",
            "    --temperature=\u001b[4mTEMPERATURE\u001b[0m\n",
            "        Type: float\n",
            "        Default: 0.6\n",
            "    --top_p=\u001b[4mTOP_P\u001b[0m\n",
            "        Type: float\n",
            "        Default: 0.9\n",
            "    --max_seq_len=\u001b[4mMAX_SEQ_LEN\u001b[0m\n",
            "        Type: int\n",
            "        Default: 512\n",
            "    --max_batch_size=\u001b[4mMAX_BATCH_SIZE\u001b[0m\n",
            "        Type: int\n",
            "        Default: 4\n",
            "    --max_gen_len=\u001b[4mMAX_GEN_LEN\u001b[0m\n",
            "        Type: Optional[Optional]\n",
            "        Default: None\n",
            "\n",
            "\u001b[1mNOTES\u001b[0m\n",
            "    You can also use flags syntax for POSITIONAL ARGUMENTS\n"
          ]
        }
      ],
      "source": [
        "!python example_chat_completion.py --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGJ3jFHrjp4"
      },
      "source": [
        "**Model architecture:**\n",
        "\n",
        "\n",
        "```\n",
        "generator = Llama.build(\n",
        "        ckpt_dir=ckpt_dir,\n",
        "        tokenizer_path=tokenizer_path,\n",
        "        max_seq_len=max_seq_len,\n",
        "        max_batch_size=max_batch_size,\n",
        "    )\n",
        "print(generator.model)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVH6EXTescPz"
      },
      "source": [
        "<div style=\"display: flex;\">\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1PPPPiitmMTLhyrDIjrGaUi7hjuQVP9sG\" alt=\"arch-code\" width=\"400\"/>\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1ekZxS4ly1yQdWz56XZSA5ysiBrii5SRG\" alt=\"arch-diagram\" width=\"400\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF7PHLM2olY2"
      },
      "source": [
        "**Run the model locally using the torchrun command below (modify parameters using help in cell above).\n",
        "To visualize attention heads, modify model.py file locally in forward function:**\n",
        "\n",
        "```\n",
        "self.printed = False  # Flag to track if print statement has been executed and print only once\n",
        "```\n",
        "... (after scores tensor created)\n",
        "\n",
        "```\n",
        "\n",
        "        if not self.printed:\n",
        "          print(\"Shape of scores:\", scores.shape)\n",
        "          print(\"Data type of scores:\", scores.dtype)\n",
        "          print(\"Minimum value of scores:\", scores.min())\n",
        "          print(\"Maximum value of scores:\", scores.max())\n",
        "          print(\"Mean of scores:\", scores.mean())\n",
        "          print(\"Standard deviation of scores:\", scores.std())\n",
        "          print(\"Sample scores:\")\n",
        "          print(\"First subset:\")\n",
        "          print(scores[:3, :3, :3, :3])\n",
        "          print(\"Last subset:\")\n",
        "          print(scores[-3:, -3:, -3:, -3:])\n",
        "          self.printed = True\n",
        "```\n",
        "The last two parameters of the scores tensor is related to the length. Current hypothesis is that the 3rd parameter is for number of tokens and 4th is for number of masks created.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obLNh2RQHbCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccab496d-4075-4d32-bf06-befb628e9baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> initializing model parallel with size 1\n",
            "> initializing ddp with size 1\n",
            "> initializing pipeline with size 1\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:747: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:431.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "Loaded in 14.07 seconds\n",
            "[128000, 10445, 1587, 6212, 5030, 30, 128001]\n",
            "User: Why does sleep matter?\n",
            "\n",
            "> Assistant: Sleep is essential for human survival. Lack of sleep is associated with serious health problems and may even be fatal. So, if we have the time, it makes sense to take advantage of it and to sleep longer.\n",
            "\n",
            "On the other hand, in the past, people had much less leisure time available. They often had to spend every minute of the day working, just to survive. This is particularly true in industrial societies, where the dominant social norm is that everyone has to work. For them, spending more time sleeping was difficult or even dangerous. However, most people\n",
            "\n",
            "==================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!torchrun --nproc_per_node 1 /content/llama3/example_chat_completion.py \\\n",
        "    --ckpt_dir /content/llama3/Meta-Llama-3-8B \\\n",
        "    --tokenizer_path /content/llama3/Meta-Llama-3-8B/tokenizer.model \\\n",
        "    --max_seq_len 128 --max_batch_size 4 --temperature 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85Rs3DyYNYyE"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['RANK'] = '1'  # rank of the current process\n",
        "# os.environ['WORLD_SIZE'] = '0'\n",
        "# os.environ['MASTER_ADDR'] = 'localhost'\n",
        "# os.environ['MASTER_PORT'] = '12355'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}